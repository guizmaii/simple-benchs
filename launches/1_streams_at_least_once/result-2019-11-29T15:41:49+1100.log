[info] Loading global plugins from /Users/jules/.sbt/1.0/plugins
[info] Loading settings for project simple-benchs-build from plugins.sbt ...
[info] Loading project definition from /Users/jules/simplemachines/workspace/simple-benchs/project
[info] Loading settings for project root from build.sbt ...
[info] Set current project to simple-benchs (in build file:/Users/jules/simplemachines/workspace/simple-benchs/)
[info] Compiling 3 Scala sources to /Users/jules/simplemachines/workspace/simple-benchs/benchs/target/scala-2.12/classes ...
[info] Done compiling.
[info] Compiling 3 Scala sources to /Users/jules/simplemachines/workspace/simple-benchs/benchs/target/scala-2.12/it-classes ...
[info] Done compiling.
15:42:01.988 [INFO ] i.g.c.c.GatlingConfiguration$ - Gatling will try to use 'gatling.conf' as custom config file.
15:42:02.416 [INFO ] a.e.s.Slf4jLogger - Slf4jLogger started
15:42:02.922 [INFO ] i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	bearer.auth.token = [hidden]
	schema.registry.url = [http://schema-registry:8081]
	basic.auth.user.info = [hidden]
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

15:42:02.934 [INFO ] i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	bearer.auth.token = [hidden]
	schema.registry.url = [http://schema-registry:8081]
	basic.auth.user.info = [hidden]
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	specific.avro.reader = false
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

15:42:02.934 [INFO ] i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	bearer.auth.token = [hidden]
	schema.registry.url = [http://schema-registry:8081]
	basic.auth.user.info = [hidden]
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

15:42:02.934 [INFO ] i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	bearer.auth.token = [hidden]
	schema.registry.url = [http://schema-registry:8081]
	basic.auth.user.info = [hidden]
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	specific.avro.reader = false
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicNameStrategy

15:42:02.935 [INFO ] i.c.k.s.KafkaAvroSerializerConfig - KafkaAvroSerializerConfig values: 
	bearer.auth.token = [hidden]
	schema.registry.url = [http://schema-registry:8081]
	basic.auth.user.info = [hidden]
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicRecordNameStrategy
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicRecordNameStrategy

15:42:02.935 [INFO ] i.c.k.s.KafkaAvroDeserializerConfig - KafkaAvroDeserializerConfig values: 
	bearer.auth.token = [hidden]
	schema.registry.url = [http://schema-registry:8081]
	basic.auth.user.info = [hidden]
	auto.register.schemas = true
	max.schemas.per.subject = 1000
	basic.auth.credentials.source = URL
	schema.registry.basic.auth.user.info = [hidden]
	bearer.auth.credentials.source = STATIC_TOKEN
	specific.avro.reader = false
	value.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicRecordNameStrategy
	key.subject.name.strategy = class io.confluent.kafka.serializers.subject.TopicRecordNameStrategy

15:42:02.970 [INFO ] o.a.k.c.p.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [kafka-1:9092, kafka-2:19092, kafka-3:29092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = simplesource.producer
	compression.type = snappy
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
	key.serializer = class io.simplesource.kafka.serialization.util.GenericSerde$1
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class io.simplesource.kafka.serialization.util.GenericSerde$1

15:42:03.065 [INFO ] o.a.k.c.u.AppInfoParser - Kafka version: 5.3.1-ce
15:42:03.065 [INFO ] o.a.k.c.u.AppInfoParser - Kafka commitId: fa27711799029b98
15:42:03.065 [INFO ] o.a.k.c.u.AppInfoParser - Kafka startTimeMs: 1575002523064
15:42:03.068 [INFO ] o.a.k.c.p.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [kafka-1:9092, kafka-2:19092, kafka-3:29092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = simplesource.producer
	compression.type = snappy
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
	key.serializer = class io.simplesource.kafka.serialization.util.GenericSerde$1
	linger.ms = 0
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.StringSerializer

15:42:03.076 [INFO ] o.a.k.c.u.AppInfoParser - Kafka version: 5.3.1-ce
15:42:03.076 [INFO ] o.a.k.c.u.AppInfoParser - Kafka commitId: fa27711799029b98
15:42:03.076 [INFO ] o.a.k.c.u.AppInfoParser - Kafka startTimeMs: 1575002523076
15:42:03.077 [WARN ] o.a.k.c.u.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=simplesource.producer
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:427)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:287)
	at io.simplesource.kafka.internal.client.KafkaRequestAPI.kakfaProducerSender(KafkaRequestAPI.java:70)
	at io.simplesource.kafka.internal.client.KafkaRequestAPI.<init>(KafkaRequestAPI.java:87)
	at io.simplesource.kafka.internal.client.KafkaCommandAPI.<init>(KafkaCommandAPI.java:37)
	at io.simplesource.kafka.client.EventSourcedClient.createCommandAPI(EventSourcedClient.java:50)
	at io.simplesource.kafka.client.EventSourcedClient.createCommandAPI(EventSourcedClient.java:44)
	at io.simplesource.benchs.it.example.Config$.appAndClient(Config.scala:71)
	at io.simplesource.benchs.it.example.Config$.avroAppAndClient(Config.scala:88)
	at io.simplesource.benchs.it.example.AvroSimulationExample.<init>(AvroSimulationExample.scala:21)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at io.gatling.app.Runner.run0(Runner.scala:74)
	at io.gatling.app.Runner.run(Runner.scala:60)
	at io.gatling.app.Gatling$.start(Gatling.scala:80)
	at io.gatling.app.Gatling$.fromArgs(Gatling.scala:46)
	at io.gatling.sbt.GatlingTask.liftedTree1$1(GatlingTask.scala:52)
	at io.gatling.sbt.GatlingTask.execute(GatlingTask.scala:51)
	at sbt.ForkMain$Run.lambda$runTest$1(ForkMain.java:304)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
15:42:03.080 [INFO ] o.a.k.c.a.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [kafka-1:9092, kafka-2:19092, kafka-3:29092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

15:42:03.092 [INFO ] o.a.k.c.u.AppInfoParser - Kafka version: 5.3.1-ce
15:42:03.092 [INFO ] o.a.k.c.u.AppInfoParser - Kafka commitId: fa27711799029b98
15:42:03.092 [INFO ] o.a.k.c.u.AppInfoParser - Kafka startTimeMs: 1575002523092
15:42:03.315 [INFO ] o.a.k.c.Metadata - [Producer clientId=simplesource.producer] Cluster ID: -YMVOfipSielpzQlmuiDng
15:42:03.315 [INFO ] o.a.k.c.Metadata - [Producer clientId=simplesource.producer] Cluster ID: -YMVOfipSielpzQlmuiDng
15:42:03.333 [INFO ] o.a.k.c.c.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 1000
	auto.offset.reset = latest
	bootstrap.servers = [kafka-1:9092, kafka-2:19092, kafka-3:29092]
	check.crcs = true
	client.dns.lookup = default
	client.id = simplesource.consumer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = response_consumer_b4ffff70
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor]
	internal.leave.group.on.close = true
	isolation.level = read_committed
	key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class io.simplesource.kafka.serialization.util.GenericSerde$2

15:42:03.334 [ERROR] i.c.m.c.i.MonitoringConsumerInterceptor - IsolationLevel=READ_COMMITTED not supported. monitoring disabled
15:42:03.356 [INFO ] o.a.k.c.u.AppInfoParser - Kafka version: 5.3.1-ce
15:42:03.356 [INFO ] o.a.k.c.u.AppInfoParser - Kafka commitId: fa27711799029b98
15:42:03.356 [INFO ] o.a.k.c.u.AppInfoParser - Kafka startTimeMs: 1575002523356
15:42:03.357 [INFO ] o.a.k.c.c.KafkaConsumer - [Consumer clientId=simplesource.consumer, groupId=response_consumer_b4ffff70] Subscribed to topic(s): user_avro_avro-benchs-aggregate-COMMAND_RESPONSE_avro-user-benchs-client
15:42:03.368 [INFO ] o.a.k.c.Metadata - [Consumer clientId=simplesource.consumer, groupId=response_consumer_b4ffff70] Cluster ID: -YMVOfipSielpzQlmuiDng
15:42:03.369 [INFO ] o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=simplesource.consumer, groupId=response_consumer_b4ffff70] Discovered group coordinator localhost:19092 (id: 2147483645 rack: null)
15:42:03.371 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=simplesource.consumer, groupId=response_consumer_b4ffff70] Revoking previously assigned partitions []
15:42:03.371 [INFO ] o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=simplesource.consumer, groupId=response_consumer_b4ffff70] (Re-)joining group
15:42:03.378 [INFO ] o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=simplesource.consumer, groupId=response_consumer_b4ffff70] (Re-)joining group
15:42:03.403 [INFO ] o.a.k.c.a.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [kafka-1:9092, kafka-2:19092, kafka-3:29092]
	client.dns.lookup = default
	client.id = 
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

15:42:03.405 [INFO ] o.a.k.c.u.AppInfoParser - Kafka version: 5.3.1-ce
15:42:03.405 [INFO ] o.a.k.c.u.AppInfoParser - Kafka commitId: fa27711799029b98
15:42:03.405 [INFO ] o.a.k.c.u.AppInfoParser - Kafka startTimeMs: 1575002523405
15:42:03.471 [INFO ] i.s.k.i.s.EventSourcedStreamsApp - Topology description Topologies:
   Sub-topology: 0
    Source: KSTREAM-SOURCE-0000000000 (topics: [user_avro_avro-benchs-aggregate-COMMAND_REQUEST])
      --> KSTREAM-KEY-SELECT-0000000012
    Processor: KSTREAM-KEY-SELECT-0000000012 (stores: [])
      --> KSTREAM-FILTER-0000000014
      <-- KSTREAM-SOURCE-0000000000
    Processor: KSTREAM-FILTER-0000000014 (stores: [])
      --> KSTREAM-SINK-0000000013
      <-- KSTREAM-KEY-SELECT-0000000012
    Sink: KSTREAM-SINK-0000000013 (topic: KSTREAM-KEY-SELECT-0000000012-repartition)
      <-- KSTREAM-FILTER-0000000014

  Sub-topology: 1
    Source: KSTREAM-SOURCE-0000000001 (topics: [user_avro_avro-benchs-aggregate-COMMAND_RESPONSE])
      --> KSTREAM-KEY-SELECT-0000000037, KSTREAM-KEY-SELECT-0000000006
    Processor: KSTREAM-KEY-SELECT-0000000006 (stores: [])
      --> KSTREAM-FILTER-0000000010
      <-- KSTREAM-SOURCE-0000000001
    Processor: KSTREAM-KEY-SELECT-0000000037 (stores: [])
      --> KSTREAM-FILTER-0000000039
      <-- KSTREAM-SOURCE-0000000001
    Processor: KSTREAM-FILTER-0000000010 (stores: [])
      --> KSTREAM-SINK-0000000009
      <-- KSTREAM-KEY-SELECT-0000000006
    Processor: KSTREAM-FILTER-0000000039 (stores: [])
      --> KSTREAM-SINK-0000000038
      <-- KSTREAM-KEY-SELECT-0000000037
    Sink: KSTREAM-SINK-0000000009 (topic: KSTREAM-REDUCE-STATE-STORE-0000000007-repartition)
      <-- KSTREAM-FILTER-0000000010
    Sink: KSTREAM-SINK-0000000038 (topic: KSTREAM-KEY-SELECT-0000000037-repartition)
      <-- KSTREAM-FILTER-0000000039

  Sub-topology: 2
    Source: KSTREAM-SOURCE-0000000026 (topics: [KSTREAM-MAPVALUES-0000000021-repartition])
      --> KSTREAM-LEFTJOIN-0000000027
    Processor: KSTREAM-LEFTJOIN-0000000027 (stores: [user_avro_avro-benchs-aggregate-AGGREGATE-STATE-STORE-0000000002])
      --> KSTREAM-FLATMAPVALUES-0000000028, KSTREAM-MAPVALUES-0000000029
      <-- KSTREAM-SOURCE-0000000026
    Processor: KSTREAM-MAPVALUES-0000000029 (stores: [])
      --> KSTREAM-FLATMAPVALUES-0000000030, KSTREAM-MAPVALUES-0000000031
      <-- KSTREAM-LEFTJOIN-0000000027
    Processor: KSTREAM-FLATMAPVALUES-0000000028 (stores: [])
      --> KSTREAM-PEEK-0000000032
      <-- KSTREAM-LEFTJOIN-0000000027
    Processor: KSTREAM-FLATMAPVALUES-0000000030 (stores: [])
      --> KSTREAM-SINK-0000000034
      <-- KSTREAM-MAPVALUES-0000000029
    Processor: KSTREAM-MAPVALUES-0000000031 (stores: [])
      --> KSTREAM-SINK-0000000036
      <-- KSTREAM-MAPVALUES-0000000029
    Processor: KSTREAM-PEEK-0000000032 (stores: [])
      --> KSTREAM-SINK-0000000033
      <-- KSTREAM-FLATMAPVALUES-0000000028
    Source: KSTREAM-SOURCE-0000000003 (topics: [user_avro_avro-benchs-aggregate-AGGREGATE])
      --> KTABLE-SOURCE-0000000004
    Sink: KSTREAM-SINK-0000000033 (topic: user_avro_avro-benchs-aggregate-EVENT)
      <-- KSTREAM-PEEK-0000000032
    Sink: KSTREAM-SINK-0000000034 (topic: user_avro_avro-benchs-aggregate-AGGREGATE)
      <-- KSTREAM-FLATMAPVALUES-0000000030
    Sink: KSTREAM-SINK-0000000036 (topic: user_avro_avro-benchs-aggregate-COMMAND_RESPONSE)
      <-- KSTREAM-MAPVALUES-0000000031
    Processor: KTABLE-SOURCE-0000000004 (stores: [user_avro_avro-benchs-aggregate-AGGREGATE-STATE-STORE-0000000002])
      --> none
      <-- KSTREAM-SOURCE-0000000003

  Sub-topology: 3
    Source: KSTREAM-SOURCE-0000000005 (topics: [user_avro_avro-benchs-aggregate-COMMAND_RESPONSE_TOPIC_MAP])
      --> KSTREAM-WINDOWED-0000000042
    Source: KSTREAM-SOURCE-0000000040 (topics: [KSTREAM-KEY-SELECT-0000000037-repartition])
      --> KSTREAM-WINDOWED-0000000041
    Processor: KSTREAM-WINDOWED-0000000041 (stores: [KSTREAM-JOINTHIS-0000000043-store])
      --> KSTREAM-JOINTHIS-0000000043
      <-- KSTREAM-SOURCE-0000000040
    Processor: KSTREAM-WINDOWED-0000000042 (stores: [KSTREAM-JOINOTHER-0000000044-store])
      --> KSTREAM-JOINOTHER-0000000044
      <-- KSTREAM-SOURCE-0000000005
    Processor: KSTREAM-JOINOTHER-0000000044 (stores: [KSTREAM-JOINTHIS-0000000043-store])
      --> KSTREAM-MERGE-0000000045
      <-- KSTREAM-WINDOWED-0000000042
    Processor: KSTREAM-JOINTHIS-0000000043 (stores: [KSTREAM-JOINOTHER-0000000044-store])
      --> KSTREAM-MERGE-0000000045
      <-- KSTREAM-WINDOWED-0000000041
    Processor: KSTREAM-MERGE-0000000045 (stores: [])
      --> KSTREAM-MAP-0000000046
      <-- KSTREAM-JOINTHIS-0000000043, KSTREAM-JOINOTHER-0000000044
    Processor: KSTREAM-MAP-0000000046 (stores: [])
      --> KSTREAM-SINK-0000000047
      <-- KSTREAM-MERGE-0000000045
    Sink: KSTREAM-SINK-0000000047 (extractor class: io.simplesource.kafka.internal.streams.topology.ResultDistributor$$Lambda$534/710843619@351b7c57)
      <-- KSTREAM-MAP-0000000046

  Sub-topology: 4
    Source: KSTREAM-SOURCE-0000000015 (topics: [KSTREAM-KEY-SELECT-0000000012-repartition])
      --> KSTREAM-LEFTJOIN-0000000016
    Processor: KSTREAM-LEFTJOIN-0000000016 (stores: [KSTREAM-REDUCE-STATE-STORE-0000000007])
      --> KSTREAM-KEY-SELECT-0000000017
      <-- KSTREAM-SOURCE-0000000015
    Processor: KSTREAM-KEY-SELECT-0000000017 (stores: [])
      --> KSTREAM-BRANCH-0000000018
      <-- KSTREAM-LEFTJOIN-0000000016
    Processor: KSTREAM-BRANCH-0000000018 (stores: [])
      --> KSTREAM-BRANCHCHILD-0000000019, KSTREAM-BRANCHCHILD-0000000020
      <-- KSTREAM-KEY-SELECT-0000000017
    Processor: KSTREAM-BRANCHCHILD-0000000019 (stores: [])
      --> KSTREAM-MAPVALUES-0000000021
      <-- KSTREAM-BRANCH-0000000018
    Processor: KSTREAM-BRANCHCHILD-0000000020 (stores: [])
      --> KSTREAM-MAPVALUES-0000000022
      <-- KSTREAM-BRANCH-0000000018
    Processor: KSTREAM-MAPVALUES-0000000021 (stores: [])
      --> KSTREAM-FILTER-0000000025
      <-- KSTREAM-BRANCHCHILD-0000000019
    Processor: KSTREAM-MAPVALUES-0000000022 (stores: [])
      --> KSTREAM-PEEK-0000000023
      <-- KSTREAM-BRANCHCHILD-0000000020
    Processor: KSTREAM-FILTER-0000000025 (stores: [])
      --> KSTREAM-SINK-0000000024
      <-- KSTREAM-MAPVALUES-0000000021
    Processor: KSTREAM-PEEK-0000000023 (stores: [])
      --> KSTREAM-SINK-0000000035
      <-- KSTREAM-MAPVALUES-0000000022
    Source: KSTREAM-SOURCE-0000000011 (topics: [KSTREAM-REDUCE-STATE-STORE-0000000007-repartition])
      --> KSTREAM-REDUCE-0000000008
    Processor: KSTREAM-REDUCE-0000000008 (stores: [KSTREAM-REDUCE-STATE-STORE-0000000007])
      --> none
      <-- KSTREAM-SOURCE-0000000011
    Sink: KSTREAM-SINK-0000000024 (topic: KSTREAM-MAPVALUES-0000000021-repartition)
      <-- KSTREAM-FILTER-0000000025
    Sink: KSTREAM-SINK-0000000035 (topic: user_avro_avro-benchs-aggregate-COMMAND_RESPONSE)
      <-- KSTREAM-PEEK-0000000023


15:42:03.479 [INFO ] o.a.k.s.StreamsConfig - StreamsConfig values: 
	application.id = avro-user-benchs-app
	application.server = 
	bootstrap.servers = [kafka-1:9092, kafka-2:19092, kafka-3:29092]
	buffered.records.per.partition = 1000
	cache.max.bytes.buffering = 10485760
	client.id = 
	commit.interval.ms = 30000
	connections.max.idle.ms = 540000
	default.deserialization.exception.handler = class org.apache.kafka.streams.errors.LogAndFailExceptionHandler
	default.key.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	default.production.exception.handler = class org.apache.kafka.streams.errors.DefaultProductionExceptionHandler
	default.timestamp.extractor = class org.apache.kafka.streams.processor.FailOnInvalidTimestamp
	default.value.serde = class org.apache.kafka.common.serialization.Serdes$ByteArraySerde
	max.task.idle.ms = 0
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	num.standby.replicas = 0
	num.stream.threads = 1
	partition.grouper = class org.apache.kafka.streams.processor.DefaultPartitionGrouper
	poll.ms = 100
	processing.guarantee = at_least_once
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	replication.factor = 3
	request.timeout.ms = 40000
	retries = 0
	retry.backoff.ms = 100
	rocksdb.config.setter = null
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	state.cleanup.delay.ms = 600000
	state.dir = /tmp/kafka-streams
	topology.optimization = none
	upgrade.from = null
	windowstore.changelog.additional.retention.ms = 86400000

15:42:03.525 [INFO ] o.a.k.c.a.AdminClientConfig - AdminClientConfig values: 
	bootstrap.servers = [kafka-1:9092, kafka-2:19092, kafka-3:29092]
	client.dns.lookup = default
	client.id = avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-admin
	connections.max.idle.ms = 300000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 120000
	retries = 5
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

15:42:03.528 [INFO ] o.a.k.c.u.AppInfoParser - Kafka version: 5.3.1-ce
15:42:03.528 [INFO ] o.a.k.c.u.AppInfoParser - Kafka commitId: fa27711799029b98
15:42:03.528 [INFO ] o.a.k.c.u.AppInfoParser - Kafka startTimeMs: 1575002523528
15:42:03.528 [INFO ] o.a.k.s.p.i.StreamThread - stream-thread [avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1] Creating restore consumer client
15:42:03.529 [INFO ] o.a.k.c.c.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = none
	bootstrap.servers = [kafka-1:9092, kafka-2:19092, kafka-3:29092]
	check.crcs = true
	client.dns.lookup = default
	client.id = avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-restore-consumer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = null
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor]
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

15:42:03.532 [INFO ] o.a.k.c.u.AppInfoParser - Kafka version: 5.3.1-ce
15:42:03.532 [INFO ] o.a.k.c.u.AppInfoParser - Kafka commitId: fa27711799029b98
15:42:03.532 [INFO ] o.a.k.c.u.AppInfoParser - Kafka startTimeMs: 1575002523532
15:42:03.534 [INFO ] o.a.k.s.p.i.StreamThread - stream-thread [avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1] Creating shared producer client
15:42:03.534 [INFO ] o.a.k.c.p.ProducerConfig - ProducerConfig values: 
	acks = 1
	batch.size = 16384
	bootstrap.servers = [kafka-1:9092, kafka-2:19092, kafka-3:29092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-producer
	compression.type = snappy
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor]
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 100
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 5
	max.request.size = 1048576
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

15:42:03.534 [INFO ] o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=simplesource.consumer, groupId=response_consumer_b4ffff70] Successfully joined group with generation 1
15:42:03.538 [INFO ] o.a.k.c.u.AppInfoParser - Kafka version: 5.3.1-ce
15:42:03.538 [INFO ] o.a.k.c.u.AppInfoParser - Kafka commitId: fa27711799029b98
15:42:03.538 [INFO ] o.a.k.c.u.AppInfoParser - Kafka startTimeMs: 1575002523538
15:42:03.538 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=simplesource.consumer, groupId=response_consumer_b4ffff70] Setting newly assigned partitions: user_avro_avro-benchs-aggregate-COMMAND_RESPONSE_avro-user-benchs-client-0, user_avro_avro-benchs-aggregate-COMMAND_RESPONSE_avro-user-benchs-client-1, user_avro_avro-benchs-aggregate-COMMAND_RESPONSE_avro-user-benchs-client-2
15:42:03.545 [INFO ] o.a.k.s.p.i.StreamThread - stream-thread [avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1] Creating consumer client
15:42:03.547 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=simplesource.consumer, groupId=response_consumer_b4ffff70] Found no committed offset for partition user_avro_avro-benchs-aggregate-COMMAND_RESPONSE_avro-user-benchs-client-0
15:42:03.547 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=simplesource.consumer, groupId=response_consumer_b4ffff70] Found no committed offset for partition user_avro_avro-benchs-aggregate-COMMAND_RESPONSE_avro-user-benchs-client-1
15:42:03.547 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=simplesource.consumer, groupId=response_consumer_b4ffff70] Found no committed offset for partition user_avro_avro-benchs-aggregate-COMMAND_RESPONSE_avro-user-benchs-client-2
15:42:03.547 [INFO ] o.a.k.c.c.ConsumerConfig - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [kafka-1:9092, kafka-2:19092, kafka-3:29092]
	check.crcs = true
	client.dns.lookup = default
	client.id = avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = avro-user-benchs-app
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = [io.confluent.monitoring.clients.interceptor.MonitoringConsumerInterceptor]
	internal.leave.group.on.close = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 1000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [org.apache.kafka.streams.processor.internals.StreamsPartitionAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	session.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

15:42:03.556 [WARN ] o.a.k.c.c.ConsumerConfig - The configuration 'admin.retries' was supplied but isn't a known config.
15:42:03.556 [WARN ] o.a.k.c.c.ConsumerConfig - The configuration 'admin.retry.backoff.ms' was supplied but isn't a known config.
15:42:03.556 [INFO ] o.a.k.c.u.AppInfoParser - Kafka version: 5.3.1-ce
15:42:03.556 [INFO ] o.a.k.c.u.AppInfoParser - Kafka commitId: fa27711799029b98
15:42:03.556 [INFO ] o.a.k.c.u.AppInfoParser - Kafka startTimeMs: 1575002523556
15:42:03.561 [INFO ] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=simplesource.consumer, groupId=response_consumer_b4ffff70] Resetting offset for partition user_avro_avro-benchs-aggregate-COMMAND_RESPONSE_avro-user-benchs-client-0 to offset 349.
15:42:03.562 [INFO ] o.a.k.s.KafkaStreams - stream-client [avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd] State transition from CREATED to REBALANCING
15:42:03.562 [INFO ] o.a.k.s.p.i.StreamThread - stream-thread [avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1] Starting
15:42:03.562 [INFO ] o.a.k.s.p.i.StreamThread - stream-thread [avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1] State transition from CREATED to STARTING
15:42:03.562 [INFO ] o.a.k.c.c.KafkaConsumer - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Subscribed to pattern: 'avro-user-benchs-app-KSTREAM-KEY-SELECT-0000000012-repartition|avro-user-benchs-app-KSTREAM-KEY-SELECT-0000000037-repartition|avro-user-benchs-app-KSTREAM-MAPVALUES-0000000021-repartition|avro-user-benchs-app-KSTREAM-REDUCE-STATE-STORE-0000000007-repartition|user_avro_avro-benchs-aggregate-AGGREGATE|user_avro_avro-benchs-aggregate-COMMAND_REQUEST|user_avro_avro-benchs-aggregate-COMMAND_RESPONSE|user_avro_avro-benchs-aggregate-COMMAND_RESPONSE_TOPIC_MAP'
15:42:03.563 [INFO ] i.s.k.i.s.EventSourcedStreamsApp - KafkaStreams now in state REBALANCING waiting until RUNNING for 5 seconds
15:42:03.566 [INFO ] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=simplesource.consumer, groupId=response_consumer_b4ffff70] Resetting offset for partition user_avro_avro-benchs-aggregate-COMMAND_RESPONSE_avro-user-benchs-client-1 to offset 356.
15:42:03.566 [INFO ] o.a.k.c.c.i.SubscriptionState - [Consumer clientId=simplesource.consumer, groupId=response_consumer_b4ffff70] Resetting offset for partition user_avro_avro-benchs-aggregate-COMMAND_RESPONSE_avro-user-benchs-client-2 to offset 382.
15:42:03.572 [INFO ] o.a.k.c.Metadata - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Cluster ID: -YMVOfipSielpzQlmuiDng
15:42:03.573 [INFO ] o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Discovered group coordinator localhost:19092 (id: 2147483645 rack: null)
15:42:03.573 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Revoking previously assigned partitions []
15:42:03.573 [INFO ] o.a.k.s.p.i.StreamThread - stream-thread [avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1] State transition from STARTING to PARTITIONS_REVOKED
15:42:03.575 [INFO ] o.a.k.c.c.KafkaConsumer - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions
15:42:03.575 [INFO ] o.a.k.s.p.i.StreamThread - stream-thread [avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1] partition revocation took 2 ms.
	suspended active tasks: []
	suspended standby tasks: []
15:42:03.575 [INFO ] o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] (Re-)joining group
15:42:03.586 [INFO ] o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] (Re-)joining group
15:42:03.643 [INFO ] o.a.k.c.Metadata - [Producer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-producer] Cluster ID: -YMVOfipSielpzQlmuiDng
15:42:03.707 [INFO ] o.a.k.s.p.i.StreamsPartitionAssignor - stream-thread [avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer] Assigned tasks to clients as {5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd=[activeTasks: ([0_0, 0_1, 1_0, 2_0, 0_2, 1_1, 2_1, 3_0, 1_2, 2_2, 3_1, 4_0, 3_2, 4_1, 4_2]) standbyTasks: ([]) assignedTasks: ([0_0, 0_1, 1_0, 2_0, 0_2, 1_1, 2_1, 3_0, 1_2, 2_2, 3_1, 4_0, 3_2, 4_1, 4_2]) prevActiveTasks: ([]) prevStandbyTasks: ([2_0, 2_1, 3_0, 3_1, 2_2, 4_0, 3_2, 4_1, 4_2]) prevAssignedTasks: ([2_0, 2_1, 3_0, 3_1, 2_2, 4_0, 3_2, 4_1, 4_2]) capacity: 1]}.
15:42:03.713 [INFO ] o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Successfully joined group with generation 3
15:42:03.714 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting newly assigned partitions: avro-user-benchs-app-KSTREAM-KEY-SELECT-0000000012-repartition-1, avro-user-benchs-app-KSTREAM-KEY-SELECT-0000000037-repartition-1, avro-user-benchs-app-KSTREAM-MAPVALUES-0000000021-repartition-1, avro-user-benchs-app-KSTREAM-REDUCE-STATE-STORE-0000000007-repartition-0, user_avro_avro-benchs-aggregate-COMMAND_RESPONSE-0, user_avro_avro-benchs-aggregate-COMMAND_RESPONSE-2, user_avro_avro-benchs-aggregate-COMMAND_RESPONSE_TOPIC_MAP-1, avro-user-benchs-app-KSTREAM-REDUCE-STATE-STORE-0000000007-repartition-2, user_avro_avro-benchs-aggregate-COMMAND_REQUEST-0, user_avro_avro-benchs-aggregate-COMMAND_REQUEST-2, user_avro_avro-benchs-aggregate-AGGREGATE-1, avro-user-benchs-app-KSTREAM-KEY-SELECT-0000000037-repartition-2, user_avro_avro-benchs-aggregate-COMMAND_RESPONSE_TOPIC_MAP-2, avro-user-benchs-app-KSTREAM-KEY-SELECT-0000000012-repartition-0, avro-user-benchs-app-KSTREAM-KEY-SELECT-0000000012-repartition-2, avro-user-benchs-app-KSTREAM-KEY-SELECT-0000000037-repartition-0, avro-user-benchs-app-KSTREAM-MAPVALUES-0000000021-repartition-2, avro-user-benchs-app-KSTREAM-MAPVALUES-0000000021-repartition-0, user_avro_avro-benchs-aggregate-COMMAND_RESPONSE_TOPIC_MAP-0, user_avro_avro-benchs-aggregate-COMMAND_RESPONSE-1, avro-user-benchs-app-KSTREAM-REDUCE-STATE-STORE-0000000007-repartition-1, user_avro_avro-benchs-aggregate-COMMAND_REQUEST-1, user_avro_avro-benchs-aggregate-AGGREGATE-2, user_avro_avro-benchs-aggregate-AGGREGATE-0
15:42:03.714 [INFO ] o.a.k.s.p.i.StreamThread - stream-thread [avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1] State transition from PARTITIONS_REVOKED to PARTITIONS_ASSIGNED
15:42:03.763 [INFO ] o.a.k.s.p.i.StreamThread - stream-thread [avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1] partition assignment took 49 ms.
	current active tasks: [0_0, 1_0, 0_1, 1_1, 0_2, 2_0, 1_2, 2_1, 3_0, 2_2, 3_1, 4_0, 3_2, 4_1, 4_2]
	current standby tasks: []
	previous active tasks: []

15:42:03.767 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition user_avro_avro-benchs-aggregate-COMMAND_RESPONSE_TOPIC_MAP-2 to the committed offset FetchPosition{offset=2448, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:29092 (id: 3 rack: null), epoch=0}}
15:42:03.767 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition avro-user-benchs-app-KSTREAM-KEY-SELECT-0000000012-repartition-0 to the committed offset FetchPosition{offset=2328, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:9092 (id: 1 rack: null), epoch=0}}
15:42:03.767 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition avro-user-benchs-app-KSTREAM-KEY-SELECT-0000000012-repartition-1 to the committed offset FetchPosition{offset=2300, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:19092 (id: 2 rack: null), epoch=0}}
15:42:03.767 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition avro-user-benchs-app-KSTREAM-KEY-SELECT-0000000037-repartition-1 to the committed offset FetchPosition{offset=315, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:9092 (id: 1 rack: null), epoch=0}}
15:42:03.767 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition avro-user-benchs-app-KSTREAM-KEY-SELECT-0000000012-repartition-2 to the committed offset FetchPosition{offset=2190, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:29092 (id: 3 rack: null), epoch=0}}
15:42:03.767 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition avro-user-benchs-app-KSTREAM-KEY-SELECT-0000000037-repartition-0 to the committed offset FetchPosition{offset=334, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:29092 (id: 3 rack: null), epoch=0}}
15:42:03.767 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition avro-user-benchs-app-KSTREAM-MAPVALUES-0000000021-repartition-2 to the committed offset FetchPosition{offset=2013, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:9092 (id: 1 rack: null), epoch=0}}
15:42:03.767 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition avro-user-benchs-app-KSTREAM-MAPVALUES-0000000021-repartition-1 to the committed offset FetchPosition{offset=1817, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:29092 (id: 3 rack: null), epoch=0}}
15:42:03.767 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition avro-user-benchs-app-KSTREAM-REDUCE-STATE-STORE-0000000007-repartition-0 to the committed offset FetchPosition{offset=334, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:9092 (id: 1 rack: null), epoch=0}}
15:42:03.767 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition avro-user-benchs-app-KSTREAM-MAPVALUES-0000000021-repartition-0 to the committed offset FetchPosition{offset=1711, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:19092 (id: 2 rack: null), epoch=0}}
15:42:03.767 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition user_avro_avro-benchs-aggregate-COMMAND_RESPONSE-0 to the committed offset FetchPosition{offset=1423, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:19092 (id: 2 rack: null), epoch=0}}
15:42:03.767 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition user_avro_avro-benchs-aggregate-COMMAND_RESPONSE_TOPIC_MAP-0 to the committed offset FetchPosition{offset=2763, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:9092 (id: 1 rack: null), epoch=0}}
15:42:03.767 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition user_avro_avro-benchs-aggregate-COMMAND_RESPONSE-2 to the committed offset FetchPosition{offset=1253, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:9092 (id: 1 rack: null), epoch=0}}
15:42:03.768 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition user_avro_avro-benchs-aggregate-COMMAND_RESPONSE_TOPIC_MAP-1 to the committed offset FetchPosition{offset=2412, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:19092 (id: 2 rack: null), epoch=0}}
15:42:03.768 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition user_avro_avro-benchs-aggregate-COMMAND_RESPONSE-1 to the committed offset FetchPosition{offset=1335, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:29092 (id: 3 rack: null), epoch=0}}
15:42:03.768 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition avro-user-benchs-app-KSTREAM-REDUCE-STATE-STORE-0000000007-repartition-2 to the committed offset FetchPosition{offset=770, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:29092 (id: 3 rack: null), epoch=0}}
15:42:03.768 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition user_avro_avro-benchs-aggregate-COMMAND_REQUEST-0 to the committed offset FetchPosition{offset=2702, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:19092 (id: 2 rack: null), epoch=0}}
15:42:03.768 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition avro-user-benchs-app-KSTREAM-REDUCE-STATE-STORE-0000000007-repartition-1 to the committed offset FetchPosition{offset=315, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:19092 (id: 2 rack: null), epoch=0}}
15:42:03.768 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition user_avro_avro-benchs-aggregate-COMMAND_REQUEST-2 to the committed offset FetchPosition{offset=2478, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:9092 (id: 1 rack: null), epoch=0}}
15:42:03.768 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition user_avro_avro-benchs-aggregate-COMMAND_REQUEST-1 to the committed offset FetchPosition{offset=2447, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:29092 (id: 3 rack: null), epoch=0}}
15:42:03.768 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition user_avro_avro-benchs-aggregate-AGGREGATE-1 to the committed offset FetchPosition{offset=1335, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:9092 (id: 1 rack: null), epoch=0}}
15:42:03.768 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition avro-user-benchs-app-KSTREAM-KEY-SELECT-0000000037-repartition-2 to the committed offset FetchPosition{offset=403, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:19092 (id: 2 rack: null), epoch=0}}
15:42:03.768 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition user_avro_avro-benchs-aggregate-AGGREGATE-2 to the committed offset FetchPosition{offset=1396, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:19092 (id: 2 rack: null), epoch=0}}
15:42:03.768 [INFO ] o.a.k.c.c.i.ConsumerCoordinator - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer, groupId=avro-user-benchs-app] Setting offset for partition user_avro_avro-benchs-aggregate-AGGREGATE-0 to the committed offset FetchPosition{offset=1443, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=localhost:29092 (id: 3 rack: null), epoch=0}}
15:42:05.931 [INFO ] o.a.k.s.s.i.RocksDBTimestampedStore - Opening store user_avro_avro-benchs-aggregate-AGGREGATE-STATE-STORE-0000000002 in regular mode
15:42:05.952 [INFO ] o.a.k.s.s.i.RocksDBTimestampedStore - Opening store user_avro_avro-benchs-aggregate-AGGREGATE-STATE-STORE-0000000002 in regular mode
15:42:06.003 [INFO ] o.a.k.s.s.i.RocksDBTimestampedStore - Opening store user_avro_avro-benchs-aggregate-AGGREGATE-STATE-STORE-0000000002 in regular mode
15:42:06.046 [INFO ] o.a.k.s.s.i.RocksDBTimestampedStore - Opening store KSTREAM-REDUCE-STATE-STORE-0000000007 in regular mode
15:42:06.087 [INFO ] o.a.k.s.s.i.RocksDBTimestampedStore - Opening store KSTREAM-REDUCE-STATE-STORE-0000000007 in regular mode
15:42:06.103 [INFO ] o.a.k.s.s.i.RocksDBTimestampedStore - Opening store KSTREAM-REDUCE-STATE-STORE-0000000007 in regular mode
15:42:06.106 [INFO ] o.a.k.c.Metadata - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-restore-consumer, groupId=null] Cluster ID: -YMVOfipSielpzQlmuiDng
15:42:06.119 [INFO ] o.a.k.c.c.KafkaConsumer - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-restore-consumer, groupId=null] Subscribed to partition(s): avro-user-benchs-app-user_avro_avro-benchs-aggregate-AGGREGATE-STATE-STORE-0000000002-changelog-1, avro-user-benchs-app-user_avro_avro-benchs-aggregate-AGGREGATE-STATE-STORE-0000000002-changelog-0, avro-user-benchs-app-KSTREAM-JOINOTHER-0000000044-store-changelog-0, avro-user-benchs-app-KSTREAM-JOINOTHER-0000000044-store-changelog-1, avro-user-benchs-app-user_avro_avro-benchs-aggregate-AGGREGATE-STATE-STORE-0000000002-changelog-2, avro-user-benchs-app-KSTREAM-JOINOTHER-0000000044-store-changelog-2, avro-user-benchs-app-KSTREAM-REDUCE-STATE-STORE-0000000007-changelog-2, avro-user-benchs-app-KSTREAM-JOINTHIS-0000000043-store-changelog-0, avro-user-benchs-app-KSTREAM-REDUCE-STATE-STORE-0000000007-changelog-1, avro-user-benchs-app-KSTREAM-JOINTHIS-0000000043-store-changelog-1, avro-user-benchs-app-KSTREAM-REDUCE-STATE-STORE-0000000007-changelog-0, avro-user-benchs-app-KSTREAM-JOINTHIS-0000000043-store-changelog-2
15:42:06.119 [INFO ] o.a.k.c.c.KafkaConsumer - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-restore-consumer, groupId=null] Seeking to offset 1335 for partition avro-user-benchs-app-user_avro_avro-benchs-aggregate-AGGREGATE-STATE-STORE-0000000002-changelog-1
15:42:06.139 [INFO ] o.a.k.s.s.i.RocksDBTimestampedStore - Opening store user_avro_avro-benchs-aggregate-AGGREGATE-STATE-STORE-0000000002 in regular mode
15:42:06.139 [INFO ] o.a.k.c.c.KafkaConsumer - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-restore-consumer, groupId=null] Seeking to offset 1442 for partition avro-user-benchs-app-user_avro_avro-benchs-aggregate-AGGREGATE-STATE-STORE-0000000002-changelog-0
15:42:06.151 [INFO ] o.a.k.s.s.i.RocksDBTimestampedStore - Opening store user_avro_avro-benchs-aggregate-AGGREGATE-STATE-STORE-0000000002 in regular mode
15:42:06.151 [INFO ] o.a.k.c.c.KafkaConsumer - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-restore-consumer, groupId=null] Seeking to offset 2780 for partition avro-user-benchs-app-KSTREAM-JOINOTHER-0000000044-store-changelog-0
15:42:06.170 [INFO ] o.a.k.c.c.KafkaConsumer - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-restore-consumer, groupId=null] Seeking to offset 2430 for partition avro-user-benchs-app-KSTREAM-JOINOTHER-0000000044-store-changelog-1
15:42:06.182 [INFO ] o.a.k.c.c.KafkaConsumer - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-restore-consumer, groupId=null] Seeking to offset 1395 for partition avro-user-benchs-app-user_avro_avro-benchs-aggregate-AGGREGATE-STATE-STORE-0000000002-changelog-2
15:42:06.196 [INFO ] o.a.k.s.s.i.RocksDBTimestampedStore - Opening store user_avro_avro-benchs-aggregate-AGGREGATE-STATE-STORE-0000000002 in regular mode
15:42:06.196 [INFO ] o.a.k.c.c.KafkaConsumer - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-restore-consumer, groupId=null] Seeking to offset 2462 for partition avro-user-benchs-app-KSTREAM-JOINOTHER-0000000044-store-changelog-2
15:42:06.214 [INFO ] o.a.k.c.c.KafkaConsumer - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-restore-consumer, groupId=null] Seeking to offset 762 for partition avro-user-benchs-app-KSTREAM-REDUCE-STATE-STORE-0000000007-changelog-2
15:42:06.232 [INFO ] o.a.k.s.s.i.RocksDBTimestampedStore - Opening store KSTREAM-REDUCE-STATE-STORE-0000000007 in regular mode
15:42:06.232 [INFO ] o.a.k.c.c.KafkaConsumer - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-restore-consumer, groupId=null] Seeking to offset 327 for partition avro-user-benchs-app-KSTREAM-JOINTHIS-0000000043-store-changelog-0
15:42:06.243 [INFO ] o.a.k.c.c.KafkaConsumer - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-restore-consumer, groupId=null] Seeking to offset 313 for partition avro-user-benchs-app-KSTREAM-REDUCE-STATE-STORE-0000000007-changelog-1
15:42:06.255 [INFO ] o.a.k.s.s.i.RocksDBTimestampedStore - Opening store KSTREAM-REDUCE-STATE-STORE-0000000007 in regular mode
15:42:06.255 [INFO ] o.a.k.c.c.KafkaConsumer - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-restore-consumer, groupId=null] Seeking to offset 314 for partition avro-user-benchs-app-KSTREAM-JOINTHIS-0000000043-store-changelog-1
15:42:06.266 [INFO ] o.a.k.c.c.KafkaConsumer - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-restore-consumer, groupId=null] Seeking to offset 330 for partition avro-user-benchs-app-KSTREAM-REDUCE-STATE-STORE-0000000007-changelog-0
15:42:06.281 [INFO ] o.a.k.s.s.i.RocksDBTimestampedStore - Opening store KSTREAM-REDUCE-STATE-STORE-0000000007 in regular mode
15:42:06.281 [INFO ] o.a.k.c.c.KafkaConsumer - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-restore-consumer, groupId=null] Seeking to offset 401 for partition avro-user-benchs-app-KSTREAM-JOINTHIS-0000000043-store-changelog-2
15:42:06.429 [INFO ] o.a.k.s.s.i.RocksDBTimestampedStore - Opening store user_avro_avro-benchs-aggregate-AGGREGATE-STATE-STORE-0000000002 in regular mode
15:42:06.456 [INFO ] o.a.k.s.s.i.RocksDBTimestampedStore - Opening store user_avro_avro-benchs-aggregate-AGGREGATE-STATE-STORE-0000000002 in regular mode
15:42:06.504 [INFO ] o.a.k.s.s.i.RocksDBTimestampedStore - Opening store user_avro_avro-benchs-aggregate-AGGREGATE-STATE-STORE-0000000002 in regular mode
15:42:06.531 [INFO ] o.a.k.s.s.i.RocksDBTimestampedStore - Opening store KSTREAM-REDUCE-STATE-STORE-0000000007 in regular mode
15:42:06.550 [INFO ] o.a.k.s.s.i.RocksDBTimestampedStore - Opening store KSTREAM-REDUCE-STATE-STORE-0000000007 in regular mode
15:42:06.569 [INFO ] o.a.k.s.s.i.RocksDBTimestampedStore - Opening store KSTREAM-REDUCE-STATE-STORE-0000000007 in regular mode
15:42:06.578 [INFO ] o.a.k.c.c.KafkaConsumer - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions
15:42:06.607 [INFO ] o.a.k.c.c.KafkaConsumer - [Consumer clientId=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-restore-consumer, groupId=null] Unsubscribed all topics or patterns and assigned partitions
15:42:06.607 [INFO ] o.a.k.s.p.i.StreamThread - stream-thread [avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1] State transition from PARTITIONS_ASSIGNED to RUNNING
15:42:06.608 [INFO ] o.a.k.s.KafkaStreams - stream-client [avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd] State transition from REBALANCING to RUNNING
15:42:07.937 [INFO ] i.c.m.c.i.MonitoringConsumerInterceptor - creating interceptor
15:42:07.978 [INFO ] i.c.m.c.i.MonitoringInterceptorConfig - MonitoringInterceptorConfig values: 
	confluent.monitoring.interceptor.publishMs = 15000
	confluent.monitoring.interceptor.topic = _confluent-monitoring

15:42:07.996 [INFO ] o.a.k.c.p.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [kafka-1:9092, kafka-2:19092, kafka-3:29092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = confluent.monitoring.interceptor.avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer
	compression.type = lz4
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 10485760
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

15:42:07.998 [INFO ] o.a.k.c.u.AppInfoParser - Kafka version: 5.3.1-ce
15:42:07.998 [INFO ] o.a.k.c.u.AppInfoParser - Kafka commitId: fa27711799029b98
15:42:07.998 [INFO ] o.a.k.c.u.AppInfoParser - Kafka startTimeMs: 1575002527998
15:42:07.999 [INFO ] i.c.m.c.i.MonitoringInterceptor - interceptor=confluent.monitoring.interceptor.avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer created for client_id=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer client_type=CONSUMER session= cluster=-YMVOfipSielpzQlmuiDng group=avro-user-benchs-app
15:42:08.300 [INFO ] i.c.m.c.i.MonitoringProducerInterceptor - creating interceptor
15:42:08.300 [INFO ] i.c.m.c.i.MonitoringInterceptorConfig - MonitoringInterceptorConfig values: 
	confluent.monitoring.interceptor.publishMs = 15000
	confluent.monitoring.interceptor.topic = _confluent-monitoring

15:42:08.300 [INFO ] o.a.k.c.p.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [kafka-1:9092, kafka-2:19092, kafka-3:29092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = confluent.monitoring.interceptor.avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-producer
	compression.type = lz4
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 10485760
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

15:42:08.302 [INFO ] o.a.k.c.u.AppInfoParser - Kafka version: 5.3.1-ce
15:42:08.302 [INFO ] o.a.k.c.u.AppInfoParser - Kafka commitId: fa27711799029b98
15:42:08.302 [INFO ] o.a.k.c.u.AppInfoParser - Kafka startTimeMs: 1575002528302
15:42:08.303 [INFO ] i.c.m.c.i.MonitoringInterceptor - interceptor=confluent.monitoring.interceptor.avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-producer created for client_id=avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-producer client_type=PRODUCER session= cluster=-YMVOfipSielpzQlmuiDng
15:42:08.506 [INFO ] o.a.k.c.Metadata - [Producer clientId=confluent.monitoring.interceptor.avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-consumer] Cluster ID: -YMVOfipSielpzQlmuiDng
15:42:08.808 [INFO ] o.a.k.c.Metadata - [Producer clientId=confluent.monitoring.interceptor.avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1-producer] Cluster ID: -YMVOfipSielpzQlmuiDng
15:42:11.907 [INFO ] i.s.k.i.s.EventSourcedStreamsApp - Streams app stable for 5 seconds. Considered up.
Simulation io.simplesource.benchs.it.example.AvroSimulationExample started...
15:42:11.958 [INFO ] i.g.c.s.w.LogFileDataWriter - Initializing
15:42:11.959 [INFO ] i.g.c.s.w.ConsoleDataWriter - Initializing
15:42:11.963 [INFO ] i.g.c.s.w.ConsoleDataWriter - Initialized
15:42:11.968 [INFO ] i.g.c.s.w.LogFileDataWriter - Initialized
15:42:12.004 [INFO ] i.c.m.c.i.MonitoringProducerInterceptor - creating interceptor
15:42:12.004 [INFO ] i.c.m.c.i.MonitoringInterceptorConfig - MonitoringInterceptorConfig values: 
	confluent.monitoring.interceptor.publishMs = 15000
	confluent.monitoring.interceptor.topic = _confluent-monitoring

15:42:12.005 [INFO ] o.a.k.c.p.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [kafka-1:9092, kafka-2:19092, kafka-3:29092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = confluent.monitoring.interceptor.simplesource.producer
	compression.type = lz4
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 10485760
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

15:42:12.007 [INFO ] o.a.k.c.u.AppInfoParser - Kafka version: 5.3.1-ce
15:42:12.007 [INFO ] o.a.k.c.u.AppInfoParser - Kafka commitId: fa27711799029b98
15:42:12.007 [INFO ] o.a.k.c.u.AppInfoParser - Kafka startTimeMs: 1575002532007
15:42:12.008 [INFO ] i.c.m.c.i.MonitoringInterceptor - interceptor=confluent.monitoring.interceptor.simplesource.producer created for client_id=simplesource.producer client_type=PRODUCER session= cluster=-YMVOfipSielpzQlmuiDng
15:42:12.036 [INFO ] i.c.m.c.i.MonitoringProducerInterceptor - creating interceptor
15:42:12.036 [INFO ] i.c.m.c.i.MonitoringInterceptorConfig - MonitoringInterceptorConfig values: 
	confluent.monitoring.interceptor.publishMs = 15000
	confluent.monitoring.interceptor.topic = _confluent-monitoring

15:42:12.036 [INFO ] o.a.k.c.p.ProducerConfig - ProducerConfig values: 
	acks = all
	batch.size = 16384
	bootstrap.servers = [kafka-1:9092, kafka-2:19092, kafka-3:29092]
	buffer.memory = 33554432
	client.dns.lookup = default
	client.id = confluent.monitoring.interceptor.simplesource.producer
	compression.type = lz4
	connections.max.idle.ms = 540000
	delivery.timeout.ms = 120000
	enable.idempotence = false
	interceptor.classes = []
	key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
	linger.ms = 500
	max.block.ms = 60000
	max.in.flight.requests.per.connection = 1
	max.request.size = 10485760
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
	receive.buffer.bytes = 32768
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 10
	retry.backoff.ms = 500
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.mechanism = GSSAPI
	security.protocol = PLAINTEXT
	send.buffer.bytes = 131072
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
	ssl.endpoint.identification.algorithm = https
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLS
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	transaction.timeout.ms = 60000
	transactional.id = null
	value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer

15:42:12.039 [INFO ] o.a.k.c.u.AppInfoParser - Kafka version: 5.3.1-ce
15:42:12.040 [INFO ] o.a.k.c.u.AppInfoParser - Kafka commitId: fa27711799029b98
15:42:12.040 [INFO ] o.a.k.c.u.AppInfoParser - Kafka startTimeMs: 1575002532039
15:42:12.040 [WARN ] o.a.k.c.u.AppInfoParser - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.producer:type=app-info,id=confluent.monitoring.interceptor.simplesource.producer
	at com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:437)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1898)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:966)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:900)
	at com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:324)
	at com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:427)
	at org.apache.kafka.clients.producer.KafkaProducer.<init>(KafkaProducer.java:270)
	at io.confluent.monitoring.clients.interceptor.MonitoringInterceptor.create(MonitoringInterceptor.java:88)
	at io.confluent.monitoring.clients.interceptor.MonitoringInterceptor.createForProducer(MonitoringInterceptor.java:158)
	at io.confluent.monitoring.clients.interceptor.MonitoringProducerInterceptor.onAcknowledgement(MonitoringProducerInterceptor.java:78)
	at org.apache.kafka.clients.producer.internals.ProducerInterceptors.onAcknowledgement(ProducerInterceptors.java:88)
	at org.apache.kafka.clients.producer.KafkaProducer$InterceptorCallback.onCompletion(KafkaProducer.java:1316)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.completeFutureAndFireCallbacks(ProducerBatch.java:227)
	at org.apache.kafka.clients.producer.internals.ProducerBatch.done(ProducerBatch.java:196)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:707)
	at org.apache.kafka.clients.producer.internals.Sender.completeBatch(Sender.java:688)
	at org.apache.kafka.clients.producer.internals.Sender.handleProduceResponse(Sender.java:596)
	at org.apache.kafka.clients.producer.internals.Sender.access$100(Sender.java:74)
	at org.apache.kafka.clients.producer.internals.Sender$1.onComplete(Sender.java:798)
	at org.apache.kafka.clients.ClientResponse.onComplete(ClientResponse.java:109)
	at org.apache.kafka.clients.NetworkClient.completeResponses(NetworkClient.java:561)
	at org.apache.kafka.clients.NetworkClient.poll(NetworkClient.java:553)
	at org.apache.kafka.clients.producer.internals.Sender.runOnce(Sender.java:335)
	at org.apache.kafka.clients.producer.internals.Sender.run(Sender.java:244)
	at java.lang.Thread.run(Thread.java:748)
15:42:12.040 [INFO ] i.c.m.c.i.MonitoringInterceptor - interceptor=confluent.monitoring.interceptor.simplesource.producer created for client_id=simplesource.producer client_type=PRODUCER session= cluster=-YMVOfipSielpzQlmuiDng
15:42:12.510 [INFO ] o.a.k.c.Metadata - [Producer clientId=confluent.monitoring.interceptor.simplesource.producer] Cluster ID: -YMVOfipSielpzQlmuiDng
15:42:12.546 [INFO ] o.a.k.c.Metadata - [Producer clientId=confluent.monitoring.interceptor.simplesource.producer] Cluster ID: -YMVOfipSielpzQlmuiDng

================================================================================
2019-11-29 15:42:16                                           5s elapsed
---- Requests ------------------------------------------------------------------
> Global                                                   (OK=1574   KO=0     )
> Avro Command 1: publishCommand                           (OK=829    KO=0     )
> Avro Command 2: publishAndQueryCommand                   (OK=745    KO=0     )

---- Avro Scenario 0 -----------------------------------------------------------
[-                                                                         ]  0%
          waiting: 99169  / active: 86     / done: 745   
================================================================================


================================================================================
2019-11-29 15:42:21                                          10s elapsed
---- Requests ------------------------------------------------------------------
> Global                                                   (OK=3255   KO=0     )
> Avro Command 1: publishCommand                           (OK=1664   KO=0     )
> Avro Command 2: publishAndQueryCommand                   (OK=1591   KO=0     )

---- Avro Scenario 0 -----------------------------------------------------------
[#-                                                                        ]  1%
          waiting: 98336  / active: 73     / done: 1591  
================================================================================


================================================================================
2019-11-29 15:42:26                                          15s elapsed
---- Requests ------------------------------------------------------------------
> Global                                                   (OK=4909   KO=0     )
> Avro Command 1: publishCommand                           (OK=2497   KO=0     )
> Avro Command 2: publishAndQueryCommand                   (OK=2412   KO=0     )

---- Avro Scenario 0 -----------------------------------------------------------
[#-                                                                        ]  2%
          waiting: 97503  / active: 85     / done: 2412  
================================================================================


================================================================================
2019-11-29 15:42:31                                          20s elapsed
---- Requests ------------------------------------------------------------------
> Global                                                   (OK=6576   KO=0     )
> Avro Command 1: publishCommand                           (OK=3331   KO=0     )
> Avro Command 2: publishAndQueryCommand                   (OK=3245   KO=0     )

---- Avro Scenario 0 -----------------------------------------------------------
[##-                                                                       ]  3%
          waiting: 96669  / active: 86     / done: 3245  
================================================================================

15:42:35.204 [INFO ] i.s.k.i.s.EventSourcedStreamsApp - Kafka Streams [org.apache.kafka.streams.KafkaStreams@7e3cd557] is shutting down
15:42:35.204 [INFO ] o.a.k.s.KafkaStreams - stream-client [avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd] State transition from RUNNING to PENDING_SHUTDOWN
15:42:35.204 [INFO ] i.s.k.i.c.KafkaRequestAPI - Request API shutting down
15:42:35.205 [INFO ] o.a.k.s.p.i.StreamThread - stream-thread [avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1] Informed to shut down
15:42:35.205 [INFO ] o.a.k.s.p.i.StreamThread - stream-thread [avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1] State transition from RUNNING to PENDING_SHUTDOWN

15:42:35.206 [INFO ] o.a.k.s.p.i.StreamThread - stream-thread [avro-user-benchs-app-5d557913-dc3f-4dfd-b4bc-3cf61d6b0cbd-StreamThread-1] Shutting down
[warn] Canceling execution...
15:42:35.234 [INFO ] o.a.k.c.c.i.AbstractCoordinator - [Consumer clientId=simplesource.consumer, groupId=response_consumer_b4ffff70] Member simplesource.consumer-3365be23-78e1-4afb-a467-59d4fe7d25f6 sending LeaveGroup request to coordinator localhost:19092 (id: 2147483645 rack: null)
[error] Total time: 38 s, completed 29/11/2019 3:42:35 PM
